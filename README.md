# üõ†Ô∏è Runbook Ops Copilot
**RAG + LangGraph para troubleshooting operacional com evid√™ncias, seguran√ßa e respostas acion√°veis.**

> Um copiloto para times de engenharia/SRE: consulta runbooks, playbooks e docs internas, sugere um plano de investiga√ß√£o e gera comandos **read-only** com pol√≠tica de seguran√ßa ‚Äî sempre com **cita√ß√µes** das fontes.

---

## ‚ú® Por que este projeto existe
Em incidentes, o que mais consome tempo √©:
- encontrar o runbook certo,
- coletar sinais (logs/m√©tricas),
- seguir um plano consistente,
- e evitar a√ß√µes destrutivas por impulso.

O **Runbook Ops Copilot** organiza esse fluxo com **RAG** e uma **m√°quina de estados (LangGraph)**, entregando respostas:
- ‚úÖ **Grounded** (com cita√ß√µes)
- ‚úÖ **A√ß√£o + contexto** (plano passo a passo)
- ‚úÖ **Seguras** (policy gate para comandos)

---

## üöÄ O que ele faz (MVP)
- üîé **Perguntas operacionais com RAG**  
  ‚ÄúPor que minha API est√° dando 502 no Nginx?‚Äù ‚Üí resposta com trechos de runbook + diagn√≥stico prov√°vel.
- üß≠ **Plano de troubleshooting (checklist)**  
  Passos numerados com o que verificar, em qual ordem, e por qu√™.
- üß™ **Comandos sugeridos com seguran√ßa**  
  Por padr√£o, gera apenas comandos **read-only** (ex.: `curl`, `journalctl`, `kubectl get`, `docker ps`).  
  Para comandos arriscados, o assistente **bloqueia** ou exige confirma√ß√£o expl√≠cita.
- üìé **Cita√ß√µes obrigat√≥rias**  
  Cada resposta vem com ‚ÄúFontes‚Äù apontando os documentos/chunks usados.
- ‚ö° **Modo r√°pido (recomendado para CPU)**  
  Voc√™ pode rodar sem gerar plano/comandos para reduzir lat√™ncia (1 chamada de LLM por request).

---

## üß† Arquitetura (LangGraph)
O fluxo √© orquestrado por um grafo de estados:

```text
User Query
   |
   v
[1] classify_intent  ---> (Q&A | Incident | Command)   (v2)
   |
   v
[2] extract_context  ---> service/env/symptoms         (v2)
   |
   v
[3] retrieve_knowledge (pgvector)
   |
   v
[4] compose_answer_with_citations
   |
   v
[5] grounding_gate
   |        \
   |         -> ask_for_more_info (when insufficient evidence)
   v
[6] generate_plan_and_commands (optional)
   |
   v
[7] safety_policy_gate (allowlist + risk)
   |
   v
Final Answer (+ citations + optional plan + optional commands)
```
>No MVP atual, os n√≥s classify_intent e extract_context podem ser implementados na v2, mantendo o core: retrieval ‚Üí resposta com cita√ß√µes ‚Üí plano/comandos opcional.

üß∞ Stack

- Backend: FastAPI (Python)
- RAG/Orquestra√ß√£o: LangChain + LangGraph
- Vector Store: PostgreSQL + pgvector
- LLM local: Ollama (Chat + Embeddings)
- UI: Streamlit (MVP) (ou Vue/Vite em v2)
- Execu√ß√£o: Docker Compose

üì¶ Estrutura do reposit√≥rio
```
.
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/                 # FastAPI routes
‚îÇ   ‚îú‚îÄ‚îÄ graph/               # LangGraph nodes + state
‚îÇ   ‚îú‚îÄ‚îÄ rag/                 # chunking, embeddings, retrieval
‚îÇ   ‚îú‚îÄ‚îÄ policies/            # command allowlist + risk rules
‚îÇ   ‚îî‚îÄ‚îÄ settings.py
‚îú‚îÄ‚îÄ ui/                      # Streamlit UI
‚îú‚îÄ‚îÄ knowledge_base/          # runbooks, playbooks, docs (md/txt/log)
‚îú‚îÄ‚îÄ docker/postgres/         # init SQL (pgvector)
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ README.md
```

‚ö° Quickstart (Docker + Ollama local)
1) Subir Postgres + Ollama + API
``` bash
docker compose up -d --build
```

2) Baixar modelos no Ollama (dentro do container)
``` bash
docker compose exec ollama ollama pull llama3.2:3b
docker compose exec ollama ollama pull nomic-embed-text
docker compose exec ollama ollama list
```

> Dica: em notebooks/CPU, modelos 3B/mini tendem a ser mais r√°pidos.

3) Indexar a base de conhecimento

Coloque seus arquivos em ./knowledge_base/ e rode:
``` bash
curl -s -X POST http://localhost:8000/api/ingest | jq
```

4) Testar a API

Health:
``` bash
curl -s http://localhost:8000/api/health
```

Chat (modo r√°pido):
``` bash
curl -s -X POST http://localhost:8000/api/chat \
  -H 'Content-Type: application/json' \
  -d '{"message":"Nginx est√° retornando 502. Por onde come√ßo?", "include_plan": false}' | jq
```

Chat (com plano + comandos):
``` bash
curl -s -X POST http://localhost:8000/api/chat \
  -H 'Content-Type: application/json' \
  -d '{"message":"Nginx 502 em produ√ß√£o. Gere plano e comandos read-only.", "include_plan": true}' | jq
```

---
üñ•Ô∏è Rodar a UI (Streamlit)

No host:
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt streamlit requests
streamlit run ui/app.py
```

---
üîê Pol√≠tica de seguran√ßa (MVP)

Este projeto n√£o executa comandos em servidores reais. Ele apenas sugere comandos e aplica pol√≠tica de risco.

Padr√£o: allowlist read-only

- ‚úÖ permitidos: curl, ping, journalctl, kubectl get/describe/logs, docker ps/logs, ps, df -h, etc.
- ‚ùå bloqueados: rm, kill, kubectl delete, DROP/DELETE, systemctl stop, iptables, etc.

Se a pergunta exigir a√ß√£o destrutiva, o assistente:

- pede confirma√ß√£o expl√≠cita e
- sugere alternativas seguras primeiro.

---
üìö Base de conhecimento (knowledge_base)

Para o projeto ficar ‚Äúportfolio-ready‚Äù, inclua 8‚Äì12 runbooks cl√°ssicos:
- API 5xx / timeout (Nginx upstream, app)
- Postgres slow queries / locks
- CPU/RAM alta (processo/container)
- Disk full
- Deploy falhou / rollback
- SSL/TLS expiring
- DNS/network issues

Cada runbook idealmente tem:
- sintomas
- hip√≥teses
- checklist
- comandos read-only
- quando escalar